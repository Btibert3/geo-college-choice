---
output: 
  html_document:
    toc: false
---

# Similar School Network

## About

Recently I came across the following post on Twitter :

> <blockquote class="twitter-tweet" data-partner="tweetdeck"><p>ICYMI last week: Facebook friendships formed btw people who checked into Brazil during June <a href="https://t.co/y9h6QcSIyd">https://t.co/y9h6QcSIyd</a> <a href="http://t.co/hk0SdHR8JN">pic.twitter.com/hk0SdHR8JN</a></p>&mdash; Sean J. Taylor (@seanjtaylor) <a href="https://twitter.com/seanjtaylor/statuses/492432734242230272">July 24, 2014</a> </blockquote>

More specifically, the map that highlights the red and blue edges to represent new friendship connections (edges) made from the World Cup.  This isn't the first time that Facebook friendships [have been overlaid onto a map](https://www.facebook.com/notes/facebook-engineering/visualizing-friendships/469716398919).

I thought it would be fun to the same with the connections of __Similar Schools__ generated by prospetive Undergraduate Students.  To do this, we simply need two things:

1.  A dataset that represents a connection - or edge - between schools that are considered similar
2.  Latitude/Longitude data for the each school

Many popular college-search sites display other institutions that are considered to be similar to the school being researched.  Personally, I have found many of these lists to be approximately similar to what I get back from the Clearinghouse.  These lists aren't perfect, but are certainly good enough for general research.


##### other
Today I came across the following post on Twitter:

> [Facebook friendships formed between people who checked in at the World Cup](https://twitter.com/seanjtaylor/status/492432734242230272/photo/1)  
  
It's not the first time that Sean has leveraged Facebook's data to explore his cool ideas: 

> [The Emotional Highs and Lows of the NFL Season](https://www.facebook.com/notes/facebook-data-science/the-emotional-highs-and-lows-of-the-nfl-season/10152033221418859)
  
  
> [NFL Fans on Facebook](https://www.facebook.com/notes/facebook-data-science/nfl-fans-on-facebook/10151298370823859)

Furthermore, Facebook has a history of highlighting (promoting?) the geo-dependency of relationships found within their platform:

> [Visualizing Friendships]("https://www.facebook.com/notes/facebook-engineering/visualizing-friendships/469716398919")


In the past, I have blogged, and presented, about the applications of [graph analysis](http://en.wikipedia.org/wiki/Graph_theory) across a wide variety of questions applicable to Enrollment Management.  

Today, I want to correlate the GPS coordinates of an insitution found in `IPEDS` (yes, this data is accessible in `IPEDS`!) to an insitution's compeitor set, which I define as the "Similar Schools" crawled from a well trafficked "College Search" site.

___more text here___




I plan on demonstrating how to crawl the web using `R` in later posts, but for time being, let's assume that we have a dataset in the following format:


## Data

I have already crawled the data that represents the relationship between schools, but more on that in a second.

The lat/long data is available through [IPEDS](http://nces.ed.gov/ipeds).  Because there is a consistent naming convention, we can simply request the URLS for the datasets that we need.  To report accurately, IPEDS is a burden for many institutions.  However, that process represents in publicly available datasets for each institution.

```{r setup}

## packages
library(plyr)
library(stringr)
library(igraph)
library(ggmap)

```

```{r getdata, warning=TRUE, message=F, eval=F}
## get the lat/long data
URL = "http://nces.ed.gov/ipeds/datacenter/data/HD2013.zip"
download.file(URL, destfile = "tmp/HD2013.zip")
unzip("tmp/HD2013.zip", exdir = "tmp")
URL = "http://nces.ed.gov/ipeds/datacenter/data/HD2013_DICT.zip"
download.file(URL, destfile = "tmp/HD2013_DICT.zip")

## get the IC
URL = "http://nces.ed.gov/ipeds/datacenter/data/IC2013.zip"
download.file(URL, destfile = "tmp/IC2013.zip")
unzip("tmp/IC2013.zip", exdir = "tmp")
URL = "http://nces.ed.gov/ipeds/datacenter/data/IC2013_DICT.zip"
download.file(URL, destfile = "tmp/IC2013_DICT.zip")

```


## Data Preparation

I don't want to keep all of the schools, so I am going to filter on the private 4-year schools that enroll `r N=300; N` or more full-time first year students.

```{r filterdata, warning=FALSE, message=F}
## read the IPEDS datasets into R
hd = read.csv("tmp/hd2013.csv", stringsAsFactors=F)
colnames(hd) = tolower(colnames(hd))

## bring in the IC dataset
ic = read.csv("tmp/ic2013.csv", stringsAsFactors=F)
colnames(ic) = tolower(colnames(ic))

## not all variabels read in correctly out of the box
ic$applfeeu = as.numeric(ic$applfeeu)
ic$enrlt = as.numeric(ic$enrlt)
ic$applcn = as.numeric(ic$applcn)
ic$admssn = as.numeric(ic$admssn)

## keep the admissions data -- inner join = only if UNITID is in both files
adm = merge(hd, ic, by.x = "unitid", by.y="unitid")

## keep only domestic states
STATES = state.abb
STATES = c(STATES, "DC")
STATES = STATES[which(! STATES %in% c('AK', 'HI'))]
adm = subset(adm, stabbr %in% STATES)

## keep only 4 year privates
adm = subset(adm, obereg %in% 1:8)
adm = subset(adm, sector == 2)
adm = subset(adm, deggrant == 1)

## must enroll more than 300 FT FY students
## N is defined inline above in the R markdown file
adm = subset(adm, enrlt >= N)

## keep only the schools that have lat/long data
adm = subset(adm, !is.na(longitud) & !is.na(latitude))


```


This results in `r nrow(adm)` 4-year private schools in our dataset.

We need to filter our network dataset to only include schools (nodes) that exist in the filtered IPEDS admissions dataset, that we called `adm` in the code above. We need to associate the from and to nodes (School A is similar to School B) with the geographic coordinates found in IPEDS.

```{r}

## bring in the network datasets (2 df's, competitors and meta)
load("~/Dropbox/Datasets/HigherEd/Cappex-April2014/parsed-data.Rdata")

## cleanup meta
meta = subset(meta, select = c(unitid, school ,rating))

## only keep schools that are in our admissions dataset
meta = subset(meta, unitid %in% adm$unitid)
edges = subset(competitors, unitid %in% adm$unitid)

## not ideal, but match the schools based on string cleaning of the school URLs
meta$url = str_join("/colleges/", 
                    str_replace_all(meta$school, pattern = " ", "-"),
                    "/")

## merge the data
meta_merge = subset(meta, select = c(url, unitid))
edges = merge(edges, meta_merge, by.x = "comp", by.y = "url", all.x=T)
edges = subset(edges, select = c(unitid.x, unitid.y, rank))
names(edges) = c("from", "to", "rank")

## ensure that we have data IPEDS data on the schools in the edges dataset
edges = subset(edges, from %in% adm$unitid)
edges = subset(edges, to %in% adm$unitid)

```


Now we need to merge ont he lat/long data


```{r addgeo, warning=FALSE, error=FALSE}

## a simple dataset for the merge
tmp_geo = subset(adm, select = c(unitid, longitud, latitude))

## merge on the lat/long for the from school
names(tmp_geo) = c("unitid", "from_long", "from_lat")
edges = merge(edges, tmp_geo, by.x="from", by.y="unitid")

## merge on the lat/long for the to school
names(tmp_geo)[2:3] = c("to_long", "to_lat")
edges = merge(edges, tmp_geo, by.x="to", by.y="unitid")

```

Let's make sure that we properly beat the data into the format we need ...

```{r echo=F, comment=NA}
head(edges)
```


## Map the data

Now we can map the data.  It may not have been obvious, but I only kep the lower 48 states, including DC.  This will make it a bit easier for mapping, although it might be cool to see how regional college selection really is.




```{r}
## http://uchicagoconsulting.wordpress.com/tag/r-ggplot2-maps-visualization/
all_states = map_data("state")
p = ggplot() + theme(panel.background = element_blank(), 
                     panel.grid = element_blank(),
                     axis.ticks = element_blank(),
                     axis.text = element_blank(),
                     axis.title = element_blank())
p = p + geom_polygon( data=all_states, 
                       aes(x=long, y=lat, group = group),
                       colour="grey", 
                       fill="grey" )
## plot the base map
p



## plot the schools
p  + geom_point(aes(adm$longitud, adm$latitude))


## plot the lines
p + geom_segment(aes(x=edges$from_long, 
                     xend = edges$to_long, 
                     y = edges$from_lat, 
                     yend = edges$to_lat),
                 alpha = .02, 
                 col = "blue")




```


Let's just keep the northeast for final detail ...

```{r ne}

## define the states
NE = c("massachusetts", 
       "rhode island", 
       "connecticut",
       "maine", 
       "new hampshire",
       "vermont",
       "new york",
       "new jersey",
       "pennsylvania",
       "maryland",
       "delaware",
       "district of columbia")
northeast = subset(all_states, region %in% NE)

## plot the map
p = ggplot() + theme(panel.background = element_blank(), 
                     panel.grid = element_blank(),
                     axis.ticks = element_blank(),
                     axis.text = element_blank(),
                     axis.title = element_blank())
p = p + geom_polygon( data=northeast, 
                       aes(x=long, y=lat, group = group),
                       colour="grey", 
                       fill="grey" )
p

## plot the schools
tmp_ne = subset(adm, obereg %in% 1:2)
p  + geom_point(aes(tmp_ne$longitud, tmp_ne$latitude))


## plot the lines
adm_ne = subset(adm, stabbr %in% c('CT', 'RI', 'MA', 'ME', 'NH', 'VT',
                                   'NY', 'NJ', 'PA', 'MD', 'DC', 'DE'))
edges_ne = subset(edges, to %in% adm_ne$unitid)
edges_ne = subset(edges_ne, from %in% adm_ne$unitid)
p + geom_segment(aes(x=edges_ne$from_long, 
                     xend = edges_ne$to_long, 
                     y = edges_ne$from_lat, 
                     yend = edges_ne$to_lat),
                 alpha = .02, 
                 col = "blue")

```

# Does it make sene to do this post as Cappex and app prediction network

# do recommendation engines too

# what about other visualizations, like igraph and arcidagram package

